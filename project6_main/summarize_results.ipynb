{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a67a3a-90b9-4a56-9254-5142d95b3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "from odell_tools import odell_hitting_strings as ohs\n",
    "\n",
    "# The following is used to generate, for each experiment, a comparison of solutions obtained from P number of runs.\n",
    "# We pass a list of strings\n",
    "# Note that the alphabet, for this case, is hard-coded for ATGC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad193339-b3bd-4cb9-a62b-bc86a41607b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data from RandomACGT_20_3000_GC72...\n",
      "Processing data from RandomACGT_20_2000_GC72...\n",
      "Processing data from RandomACGT_10_2000_GC72...\n",
      "Processing data from RandomACGT_20_5000_GC72...\n",
      "Processing data from RandomACGT_10_1000_GC72...\n",
      "Processing data from RandomACGT_30_3000_GC72...\n",
      "Processing data from RandomACGT_30_1000_GC72...\n",
      "Processing data from RandomACGT_10_3000_GC72...\n",
      "Processing data from RandomACGT_20_4000_GC72...\n",
      "Processing data from RandomACGT_20_1000_GC72...\n",
      "Processing data from RandomACGT_10_4000_GC72...\n",
      "Processing data from RandomACGT_30_5000_GC72...\n",
      "Processing data from RandomACGT_30_4000_GC72...\n",
      "                   instance result_summary  min_hamming_distance  \\\n",
      "0   RandomACGT_20_3000_GC72           best           2173.000000   \n",
      "1   RandomACGT_20_3000_GC72            avg           2179.620000   \n",
      "2   RandomACGT_20_2000_GC72           best           1429.000000   \n",
      "3   RandomACGT_20_2000_GC72            avg           1442.140000   \n",
      "4   RandomACGT_10_2000_GC72           best           1442.000000   \n",
      "5   RandomACGT_10_2000_GC72            avg           1442.040000   \n",
      "6   RandomACGT_20_5000_GC72           best           3626.000000   \n",
      "7   RandomACGT_20_5000_GC72            avg           3652.360000   \n",
      "8   RandomACGT_10_1000_GC72           best            708.000000   \n",
      "9   RandomACGT_10_1000_GC72            avg            708.460000   \n",
      "10  RandomACGT_30_3000_GC72           best           2182.000000   \n",
      "11  RandomACGT_30_3000_GC72            avg           2174.780000   \n",
      "12  RandomACGT_30_1000_GC72           best            706.000000   \n",
      "13  RandomACGT_30_1000_GC72            avg            706.520000   \n",
      "14  RandomACGT_10_3000_GC72           best           2160.000000   \n",
      "15  RandomACGT_10_3000_GC72            avg           2174.940000   \n",
      "16  RandomACGT_20_4000_GC72           best           2907.000000   \n",
      "17  RandomACGT_20_4000_GC72            avg           2915.620000   \n",
      "18  RandomACGT_20_1000_GC72           best            707.000000   \n",
      "19  RandomACGT_20_1000_GC72            avg            708.866667   \n",
      "20  RandomACGT_10_4000_GC72           best           2884.000000   \n",
      "21  RandomACGT_10_4000_GC72            avg           2917.440000   \n",
      "22  RandomACGT_30_5000_GC72           best           3638.000000   \n",
      "23  RandomACGT_30_5000_GC72            avg           3655.000000   \n",
      "24  RandomACGT_30_4000_GC72           best           2902.000000   \n",
      "25  RandomACGT_30_4000_GC72            avg           2912.180000   \n",
      "\n",
      "    max_hamming_distance  lambda(average)     runtime  \n",
      "0            2258.000000      2210.950000  173.890432  \n",
      "1            2261.320000      2220.611000  174.396052  \n",
      "2            1497.000000      1468.150000  169.414045  \n",
      "3            1508.120000      1475.562000  171.408986  \n",
      "4            1492.000000      1462.800000  123.533803  \n",
      "5            1501.100000      1471.578000  154.079262  \n",
      "6            3780.000000      3696.550000  182.486320  \n",
      "7            3769.060000      3710.277000  186.222603  \n",
      "8             745.000000       724.400000  177.029217  \n",
      "9             753.320000       730.228000  181.252418  \n",
      "10           2261.000000      2214.933333  175.901728  \n",
      "11           2269.860000      2222.195333  176.102432  \n",
      "12            748.000000       728.866667  166.752287  \n",
      "13            760.080000       733.588667  166.795458  \n",
      "14           2263.000000      2205.300000  180.622366  \n",
      "15           2253.120000      2214.400000  187.320176  \n",
      "16           3015.000000      2955.450000  177.388628  \n",
      "17           3016.440000      2964.798000  177.295461  \n",
      "18            766.000000       729.100000  194.102551  \n",
      "19            761.133333       733.306667  183.627542  \n",
      "20           2991.000000      2942.100000  180.657372  \n",
      "21           3000.600000      2959.916000  180.710844  \n",
      "22           3781.000000      3699.033333  184.880301  \n",
      "23           3772.560000      3713.778000  185.198684  \n",
      "24           2991.000000      2952.533333  198.323140  \n",
      "25           3020.780000      2968.022667  202.436361  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def plot_string_heatmap_with_legend(strings):\n",
    "    # Determine the length of the strings (assuming all strings are of equal length)\n",
    "    string_length = len(strings[0])\n",
    "    \n",
    "    # Create a mapping for characters to numeric values for color encoding\n",
    "    # This is to generate a heatmap, but the colors only signify the character identity; we'll represent this in the legend\n",
    "    unique_chars = sorted(set(\"\".join(strings)))  # Get unique characters in sorted order\n",
    "    char_to_num = {char: i for i, char in enumerate(unique_chars)}\n",
    "    num_to_char = {i: char for char, i in char_to_num.items()}  # Reverse mapping for legend\n",
    "\n",
    "    # Initialize a matrix to store the numeric values for each string's characters\n",
    "    color_matrix = np.zeros((len(strings), string_length))\n",
    "    \n",
    "    # Fill the matrix with numeric values based on character encoding\n",
    "    # Each position in a string, therefore, will get a color based on character, for easy visualization.\n",
    "    for i, string in enumerate(strings):\n",
    "        color_matrix[i] = [char_to_num[char] for char in string]\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(20, len(strings) * 0.3 + 2))\n",
    "    sns.heatmap(color_matrix, annot=False, cmap=\"viridis\", cbar=False, xticklabels=False, yticklabels=range(1, len(strings) + 1))\n",
    "    plt.xlabel(\"Position in String\")\n",
    "    plt.ylabel(\"Solution String\")\n",
    "    plt.title(\"Solution Population Heatmap\")\n",
    "    \n",
    "    # Create a custom legend, where we use the actual alphabet letters instead of numbers\n",
    "    legend_elements = [Patch(facecolor=sns.color_palette(\"viridis\", len(unique_chars))[i], \n",
    "                             label=num_to_char[i]) for i in range(len(unique_chars))]\n",
    "    \n",
    "    plt.legend(handles=legend_elements, title=\"Characters\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "\n",
    "\n",
    "def plot_match_count_heatmap(strings, experiment_name):\n",
    "    # Determine the length of the strings (assuming all strings are of equal length)\n",
    "    string_length = len(strings[0])\n",
    "    \n",
    "    # Initialize a list to store match counts for each position\n",
    "    match_counts = []\n",
    "\n",
    "    # Calculate the match count for each position\n",
    "    for pos in range(string_length):\n",
    "        # Collect all characters at this position across strings\n",
    "        chars_at_pos = [string[pos] for string in strings]\n",
    "        # Find the most common character count\n",
    "        most_common_count = Counter(chars_at_pos).most_common(1)[0][1]\n",
    "        match_counts.append(most_common_count)\n",
    "    \n",
    "    # Convert match counts to a 2D array with one row for heatmap compatibility\n",
    "    match_counts_array = np.array([match_counts])\n",
    "\n",
    "    # Plot the 1D heatmap\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    # I disable x-ticks, as in the previous function, because we have TOO many positions in our strings. It's cluttered.\n",
    "    sns.heatmap(match_counts_array, annot=True, cmap=\"YlGnBu\", cbar=True, xticklabels=False, yticklabels=False)\n",
    "    plt.ylabel(experiment_name, fontsize = 5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The main.py script for Project 6 will have produced a .csv file that summarizes the results of all runs.\n",
    "# This summarized result simply is a csv file that has a run's best solution's fitness data appended to it.\n",
    "# Thus, we can get a population of P solutions from P total runs.\n",
    "# This code block will simply summarize the results of ALL experiments (like a summary of summaries).\n",
    "# Each experiment will also have all P solutions added to a strings list.\n",
    "# This will be used to construct a heatmap that visualizes the most common matches between the solution strings.\n",
    "# This may be a helpful prerequisite for thinking about combining solutions.\n",
    "# But it may also be a way to visualize the extend to which different GA runs converge in solutions.\n",
    "# That is, will multiple runs have many common matches at each kth position?\n",
    "\n",
    "\n",
    "# Initialize a list to collect results as dictionaries\n",
    "# We can later convert this list of dictionary to a DataFrame\n",
    "results_list = []\n",
    "\n",
    "# To be passed as an argument to our heatmap function for all instances\n",
    "all_strings = []\n",
    "\n",
    "\n",
    "# Get all the experiment directories in the results directory\n",
    "# Generally, each experiment will be named after the .csp file instance\n",
    "for experiment_dir in os.listdir('results/'):\n",
    "    experiment_path = os.path.join('results', experiment_dir)\n",
    "    \n",
    "    if os.path.isdir(experiment_path):\n",
    "        # Look in the experiment directory....\n",
    "\n",
    "        print(f\"Processing data from {experiment_dir}...\")\n",
    "        \n",
    "        # Initialize lists to store data for averaging\n",
    "        min_hamming_distances = []\n",
    "        max_hamming_distances = []\n",
    "        lambdas = []\n",
    "        runtimes = []\n",
    "\n",
    "        # For experiment-specific heatmap\n",
    "        strings = []\n",
    "        \n",
    "        # Grab the names of all files and directories in the experiment directory.\n",
    "        # Of course, the only .csv that I've coded to be saved here is the run_solutions_fitness_data.csv\n",
    "        run_solution_path = os.path.join(experiment_path, 'run_solutions_fitness_data.csv')\n",
    "\n",
    "        # Read the CV and assign to df\n",
    "        df = pd.read_csv(run_solution_path)\n",
    "\n",
    "\n",
    "        # Break the df apart into lists, each containing a column's data\n",
    "        # Extend DataFrame column to lists.\n",
    "        # Simple way is to convert df columns to list using .tolist()\n",
    "        # Then extend to our empty list.\n",
    "        min_hamming_distances.extend(df['min_hamming_distance'].tolist())\n",
    "        max_hamming_distances.extend(df['max_hamming_distance'].tolist())\n",
    "        lambdas.extend(df['lambda(average)'].tolist())\n",
    "        runtimes.extend(df['runtime'].tolist())\n",
    "        strings.extend(df['solution_string'].tolist())\n",
    "\n",
    "        # For creating a matchcount heatmap for ALL instances\n",
    "        all_strings.append(strings)\n",
    "        \n",
    "        plot_string_heatmap_with_legend(strings)\n",
    "        plt.savefig(experiment_path + '/solution_strings_heatmap.png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        plot_match_count_heatmap(strings, experiment_dir)\n",
    "        plt.savefig(experiment_path + '/solution_strings_matchcount.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Calculate statistics for 'best' result\n",
    "        # First, we find index of whichever row has the smallest average value\n",
    "        best_index = lambdas.index(min(lambdas))\n",
    "\n",
    "        # Use the index of the minimum average ('best') to get the other data values, which will have same index\n",
    "        best_min_hamming_distance = min_hamming_distances[best_index]\n",
    "        best_max_hamming_distance = max_hamming_distances[best_index]\n",
    "        best_lambda = lambdas[best_index]\n",
    "        best_runtime = runtimes[best_index] # THIS IS A SPECIFIC RUNTIME FOR THE RUN THAT GENERATED THE BEST\n",
    "        \n",
    "        # Calculate statistics for 'avg' result\n",
    "        # These are straight forward.\n",
    "        avg_min_hamming_distance = sum(min_hamming_distances) / len(min_hamming_distances)\n",
    "        avg_max_hamming_distance = sum(max_hamming_distances) / len(max_hamming_distances)\n",
    "        avg_lambda = sum(lambdas) / len(lambdas)\n",
    "        avg_runtime = sum(runtimes) / len(runtimes) # THIS IS AN AVERAGE RUNTIME FROM ALL RUNS\n",
    "\n",
    "\n",
    "        # The reason for the following two is this:\n",
    "        # For each instance, I want the best solution's fitness data (best -> based on min average(lambda))\n",
    "        # Also, for each instance, I want the average solution fitness of the runs.\n",
    "        # This is a common table to see in primary literature\n",
    "\n",
    "        \n",
    "        # Add 'best' result to the results list\n",
    "        # note that the runtime here is specific\n",
    "        results_list.append({\n",
    "            'instance': experiment_dir,\n",
    "            'result_summary': 'best',\n",
    "            'min_hamming_distance': best_min_hamming_distance,\n",
    "            'max_hamming_distance': best_max_hamming_distance,\n",
    "            'lambda(average)': best_lambda,\n",
    "            'runtime': best_runtime\n",
    "        })\n",
    "        \n",
    "        # Add 'avg' result to the results list\n",
    "        results_list.append({\n",
    "            'instance': experiment_dir,\n",
    "            'result_summary': 'avg',\n",
    "            'min_hamming_distance': avg_min_hamming_distance,\n",
    "            'max_hamming_distance': avg_max_hamming_distance,\n",
    "            'lambda(average)': avg_lambda,\n",
    "            'runtime': avg_runtime\n",
    "        })\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame, nice and easy.\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Print to double-check\n",
    "print(results_df)\n",
    "\n",
    "# save the DataFrame to a CSV file. I can easily use this to add to a report.\n",
    "results_df.to_csv('results_summary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887c95dd-90ed-4ac6-8b78-0e0b2c0036c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RandomACGT_20_3000_GC72\n",
      "Loading aggregated solution.\n",
      "3000\n",
      "Loading single best of GA...\n",
      "3000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_20_2000_GC72\n",
      "Loading aggregated solution.\n",
      "2000\n",
      "Loading single best of GA...\n",
      "2000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_10_2000_GC72\n",
      "Loading aggregated solution.\n",
      "2000\n",
      "Loading single best of GA...\n",
      "2000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_20_5000_GC72\n",
      "Loading aggregated solution.\n",
      "5000\n",
      "Loading single best of GA...\n",
      "5000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_10_1000_GC72\n",
      "Loading aggregated solution.\n",
      "1000\n",
      "Loading single best of GA...\n",
      "1000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_30_3000_GC72\n",
      "Loading aggregated solution.\n",
      "3000\n",
      "Loading single best of GA...\n",
      "3000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_30_1000_GC72\n",
      "Loading aggregated solution.\n",
      "1000\n",
      "Loading single best of GA...\n",
      "1000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_10_3000_GC72\n",
      "Loading aggregated solution.\n",
      "3000\n",
      "Loading single best of GA...\n",
      "3000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_20_4000_GC72\n",
      "Loading aggregated solution.\n",
      "4000\n",
      "Loading single best of GA...\n",
      "4000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_20_1000_GC72\n",
      "Loading aggregated solution.\n",
      "1000\n",
      "Loading single best of GA...\n",
      "1000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_10_4000_GC72\n",
      "Loading aggregated solution.\n",
      "4000\n",
      "Loading single best of GA...\n",
      "4000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_30_5000_GC72\n",
      "Loading aggregated solution.\n",
      "5000\n",
      "Loading single best of GA...\n",
      "5000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing RandomACGT_30_4000_GC72\n",
      "Loading aggregated solution.\n",
      "4000\n",
      "Loading single best of GA...\n",
      "4000\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Writing final aggregated summary to \"results/aggregation_summary.csv\"\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# Process results of aggregations!\n",
    "#\n",
    "#################################\n",
    "\n",
    "# For the 'woc_results' aggregations, we need an additional step of averaging these and taking an SEM.\n",
    "\n",
    "\n",
    "# Let's process the 'results' aggregations first. Note that these only have a single woc solution instance.\n",
    "# We get the data by first loading the CSP problems associated with that instances.\n",
    "\n",
    "df = pd.read_csv('results/aggregated_solutions.csv')\n",
    "\n",
    "# Main data structure to hold ALL data before converting to DataFrame and writing to CSV\n",
    "summary = []\n",
    "\n",
    "\n",
    "# This holds the instance names and strings of our solutions...\n",
    "aggregated_solution_strings = []\n",
    "best_solution_strings = []\n",
    "instances = []\n",
    "\n",
    "# We hold the solution data here.\n",
    "# For the single_best:\n",
    "single_min = []\n",
    "single_max = []\n",
    "single_total = []\n",
    "single_avg = []\n",
    "\n",
    "# For the aggregated solution:\n",
    "agg_min = []\n",
    "agg_max = []\n",
    "agg_total = []\n",
    "agg_avg = []\n",
    "\n",
    "aggregated_solution_strings.extend(df['aggregated_solution_string'].tolist())\n",
    "best_solution_strings.extend(df['single_best_string'].tolist())\n",
    "instances.extend(df['experiment_name'].tolist())\n",
    "\n",
    "for index, instance in enumerate(instances):\n",
    "    print(f'Processing {instance}')\n",
    "    csp = ohs.ClosestStringProblem(load_file = 'data/' + instance + '.csp')\n",
    "\n",
    "    # Instantiate each solution string\n",
    "    print('Loading aggregated solution.')\n",
    "    aggregated_solution = ohs.SolutionString(string = aggregated_solution_strings[index])\n",
    "\n",
    "\n",
    "    print('Loading single best of GA...')\n",
    "    single_best = ohs.SolutionString(string = best_solution_strings[index])\n",
    "\n",
    "    \n",
    "    print('Evaluating fitness...')\n",
    "    aggregated_solution.evaluate_fitness(csp)\n",
    "    single_best.evaluate_fitness(csp)\n",
    "\n",
    "    print('Finished evaluating fitness. Now writing data...')\n",
    "\n",
    "    # Access avg, total, min and max distance, in that order...\n",
    "    avg, tot, min, max = single_best.fitness\n",
    "    single_avg.append(avg)\n",
    "    single_total.append(tot)\n",
    "    single_min.append(min)\n",
    "    single_max.append(max)\n",
    "\n",
    "    avg, tot, min, max = aggregated_solution.fitness\n",
    "    agg_avg.append(avg)\n",
    "    agg_total.append(tot)\n",
    "    agg_min.append(min)\n",
    "    agg_max.append(max)\n",
    "\n",
    "    # Bring all the data together\n",
    "    summary.append({\n",
    "        'instance': instances[index],\n",
    "    \n",
    "        'single_best_min': single_min[index],\n",
    "        'single_best_max': single_max[index],\n",
    "        'single_best_avg': single_avg[index],\n",
    "        'single_best_total': single_total[index],\n",
    "\n",
    "        'aggregated_min': agg_min[index],\n",
    "        'aggregated_max': agg_max[index],\n",
    "        'aggregated_avg': agg_avg[index],\n",
    "        'aggregated_total': agg_total[index]\n",
    "    })\n",
    "\n",
    "# Write the final summary for the aggregations\n",
    "print('Writing final aggregated summary to \"results/aggregation_summary.csv\"')\n",
    "df = pd.DataFrame(summary)\n",
    "df.to_csv('results/aggregation_summary.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6fbc8c-267e-4126-84a0-a374aa80a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing crowd member RandomACGT_2_2_uniform_TEST_woc_run_0\n",
      "Loading aggregated solution.\n",
      "Loading single best of GA...\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Processing crowd member RandomACGT_2_2_uniform_TEST_woc_run_1\n",
      "Loading aggregated solution.\n",
      "Loading single best of GA...\n",
      "Evaluating fitness...\n",
      "Finished evaluating fitness. Now writing data...\n",
      "Writing final aggregated summary to \"results/aggregation_summary.csv\"\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# Process results of WoC RUNS aggregations!\n",
    "#\n",
    "#################################\n",
    "\n",
    "df = pd.read_csv('woc_results/aggregated_solutions.csv')\n",
    "\n",
    "# Main data structure to hold ALL data before converting to DataFrame and writing to CSV\n",
    "summary = []\n",
    "\n",
    "\n",
    "# This holds the instance names and strings of our solutions...\n",
    "aggregated_solution_strings = []\n",
    "best_solution_strings = []\n",
    "instances = []\n",
    "\n",
    "# We hold the solution data here.\n",
    "# For the single_best:\n",
    "single_min = []\n",
    "single_max = []\n",
    "single_total = []\n",
    "single_avg = []\n",
    "\n",
    "# For the aggregated solution:\n",
    "agg_min = []\n",
    "agg_max = []\n",
    "agg_total = []\n",
    "agg_avg = []\n",
    "\n",
    "aggregated_solution_strings.extend(df['aggregated_solution_string'].tolist())\n",
    "best_solution_strings.extend(df['single_best_string'].tolist())\n",
    "instances.extend(df['experiment_name'].tolist())\n",
    "\n",
    "# Here, we bring the CSP object outside the loop. \n",
    "# I'm doing WoC+GA experiments one at a time.\n",
    "# Thus, I will simply pull all .csv from the woc_data.\n",
    "# In actual practice, I will only move a single .csp file into the woc_data folder one at a time.\n",
    "\n",
    "csp_file = glob.glob('woc_data/*.csp')[0]\n",
    "\n",
    "csp = ohs.ClosestStringProblem(load_file = csp_file)\n",
    "\n",
    "\n",
    "for index, instance in enumerate(instances):\n",
    "    print(f'Processing crowd member {instance}')\n",
    "\n",
    "\n",
    "    # Instantiate each solution string\n",
    "    print('Loading aggregated solution.')\n",
    "    aggregated_solution = ohs.SolutionString(string = aggregated_solution_strings[index])\n",
    "\n",
    "\n",
    "    print('Loading single best of GA...')\n",
    "    single_best = ohs.SolutionString(string = best_solution_strings[index])\n",
    "\n",
    "    \n",
    "    print('Evaluating fitness...')\n",
    "    aggregated_solution.evaluate_fitness(csp)\n",
    "    single_best.evaluate_fitness(csp)\n",
    "\n",
    "    print('Finished evaluating fitness. Now writing data...')\n",
    "\n",
    "    # Access avg, total, min and max distance, in that order...\n",
    "    avg, tot, min, max = single_best.fitness\n",
    "    single_avg.append(avg)\n",
    "    single_total.append(tot)\n",
    "    single_min.append(min)\n",
    "    single_max.append(max)\n",
    "\n",
    "    avg, tot, min, max = aggregated_solution.fitness\n",
    "    agg_avg.append(avg)\n",
    "    agg_total.append(tot)\n",
    "    agg_min.append(min)\n",
    "    agg_max.append(max)\n",
    "\n",
    "    # Bring all the data together\n",
    "    summary.append({\n",
    "        'instance': instances[index],\n",
    "    \n",
    "        'single_best_min': single_min[index],\n",
    "        'single_best_max': single_max[index],\n",
    "        'single_best_avg': single_avg[index],\n",
    "        'single_best_total': single_total[index],\n",
    "\n",
    "        'aggregated_min': agg_min[index],\n",
    "        'aggregated_max': agg_max[index],\n",
    "        'aggregated_avg': agg_avg[index],\n",
    "        'aggregated_total': agg_total[index]\n",
    "    })\n",
    "\n",
    "# Write the final summary for the aggregations\n",
    "print('Writing final aggregated summary to \"results/aggregation_summary.csv\"')\n",
    "df = pd.DataFrame(summary)\n",
    "df.to_csv('woc_results/aggregation_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f528ec-53e2-4ed0-b37d-0bf68ad20cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
